from pinecone import Pinecone, ServerlessSpec
import json
from pathlib import Path
from tqdm import tqdm
from dotenv import load_dotenv
import os
import re
import numpy as np
from openai import OpenAI

load_dotenv()
print("\nğŸ”¥ PINCONE_API_KEY ë¡œë“œë¨?:", os.getenv("PINCONE_API_KEY"))
print("\nğŸ”¥ OPENAI_API_KEY ë¡œë“œë¨?:", os.getenv("OPENAI_API_KEY"))

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Pinecone ì´ˆê¸°í™”
pc = Pinecone(api_key=os.getenv("PINCONE_API_KEY"))
index_name = "bio-paper-index"

if index_name in pc.list_indexes().names():
    pc.delete_index(index_name)

pc.create_index(
    name=index_name,
    dimension=1536,  # OpenAI text-embedding-3-small ëª¨ë¸ì˜ ì°¨ì›
    metric="cosine",
    spec=ServerlessSpec(cloud="aws", region="us-east-1")
)

index = pc.Index(index_name)

# ë°ì´í„° ë¡œë“œ
json_path = Path(__file__).parent.parent / 'data' / 'bio_research_nested.json'
with open(json_path, "r", encoding="utf-8") as f:
    data = json.load(f)

def sanitize_id(raw_id: str) -> str:
    return re.sub(r"[^a-zA-Z0-9_\-]", "_", raw_id)[:64]

def get_embedding(text: str) -> list:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ì–»ìŠµë‹ˆë‹¤."""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

print("\nğŸ“¦ ë²¡í„° ìƒì„± ë° ì—…ë¡œë“œ ì¤‘...")
vectors_to_upsert = []
vector_count = 0

for user in tqdm(data, desc="ì‚¬ìš©ì ì²˜ë¦¬ ì¤‘"):
    user_id = user["user_id"]
    for paper in user["papers"]:
        # ë…¼ë¬¸ í…ìŠ¤íŠ¸ ì¤€ë¹„
        text = (paper.get("title", "") + "\n" + paper.get("abstract", "") + "\n" +
                " ".join(paper.get("equipments", [])) + "\n" + " ".join(paper.get("reagents", [])))
        
        if not text.strip():
            continue
            
        # ì„ë² ë”© ìƒì„±
        vector = get_embedding(text)
        
        # ID ìƒì„±
        raw_id = f"{user_id}_{paper['title'][:50].strip()}"
        doc_id = sanitize_id(raw_id)
        
        # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        metadata = {
            "user_id": user["user_id"],
            "title": paper.get("title", ""),
            "abstract": paper.get("abstract", ""),
            "year": paper.get("year", ""),
            "journal": paper.get("journal", ""),
            "equipments": paper.get("equipments", []),
            "reagents": paper.get("reagents", [])
        }
        
        vectors_to_upsert.append({
            "id": doc_id,
            "values": vector,
            "metadata": metadata
        })
        vector_count += 1
        
        if len(vectors_to_upsert) >= 10:
            index.upsert(vectors=vectors_to_upsert)
            print(f"\nğŸ“Š ì¤‘ê°„ ìƒíƒœ - í˜„ì¬ê¹Œì§€ ì—…ë¡œë“œëœ ë²¡í„° ìˆ˜: {vector_count}")
            print("ğŸ§  í˜„ì¬ ì¸ë±ìŠ¤ ìƒíƒœ:", index.describe_index_stats())
            vectors_to_upsert = []

if vectors_to_upsert:
    index.upsert(vectors=vectors_to_upsert)
    print(f"\nğŸ“Š ì¤‘ê°„ ìƒíƒœ - í˜„ì¬ê¹Œì§€ ì—…ë¡œë“œëœ ë²¡í„° ìˆ˜: {vector_count}")
    print("ğŸ§  í˜„ì¬ ì¸ë±ìŠ¤ ìƒíƒœ:", index.describe_index_stats())

print(f"\nâœ… ì´ {vector_count}ê°œì˜ ë²¡í„°ê°€ Pineconeì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("\nğŸ§  ìµœì¢… ì¸ë±ìŠ¤ ìƒíƒœ:", index.describe_index_stats())

def get_recommendations(query_text, top_k=5):
    """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¶”ì²œì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not query_text.strip():
        print("ğŸš¨ ìœ íš¨í•œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì—†ìŒ!")
        return []

    # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìƒì„±
    query_vector = get_embedding(query_text)
    print(f"ğŸ§ª ë²¡í„° í‰ê· : {np.mean(query_vector):.4f}, ë¶„ì‚°: {np.var(query_vector):.4f}")

    # Pineconeì—ì„œ ìœ ì‚¬í•œ ë²¡í„° ê²€ìƒ‰
    results = index.query(vector=query_vector, top_k=top_k, include_metadata=True)

    print(f"ğŸ“Š ìœ ì‚¬í•œ ë¬¸ì„œ {len(results.matches)}ê°œ ë°œê²¬")
    recommended_users = []
    for match in results.matches:
        user_id = match.metadata.get("user_id")
        print(f"âœ… ì¶”ì²œ: {user_id} | ì œëª©: {match.metadata.get('title')} | score: {match.score:.4f}")
        if user_id not in recommended_users:
            recommended_users.append(user_id)

    return recommended_users

if __name__ == "__main__":
    queries = ["ì‹ ê²½ì„¸í¬", "ì¤„ê¸°ì„¸í¬", "ì„¸í¬", "ë©´ì—­", "ë‹¨ë°±ì§ˆ", "DNA"]
    for q in queries:
        print("\n" + "="*60)
        print(f"ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸: {q}")
        result = get_recommendations(q)
        print(f"ğŸ”— ì¶”ì²œëœ ì‚¬ìš©ì: {result}")